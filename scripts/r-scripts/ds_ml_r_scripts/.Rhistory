install.packages(c('caret',
'skimr'
, 'RANN'
, 'randomForest'
, 'fastAdaboost'
, 'gbm'
, 'xgboost'
, 'caretEnsemble'
, 'C50'
, 'earth')
)
library(caret)
installr::updater()
library(caret)
# the orange juice customer data file ----
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
View(orange)
saveRDS(object = orange, file = '../../../data/orange_juice_customer_data')
saveRDS(object = orange, file = '../../../data/orange_juice_customer_data.rdata')
saveRDS(object = orange, file = '../../../data/orange_juice_customer_data.csv')
saveRDS(object = orange, file = '../../../data/orange_juice_customer_data.rds')
saveRDS(object = orange, file = '../../../data/orange_juice_customer_data.rdata')
# the orange juice customer data file ----
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
saveRDS(object = orange, file = '../../../data/orange_juice_customer_data.rdata')
load("C:/Users/Azam/GitRepositories/ds_ml/data/orange_juice_customer_data.rdata")
write.csv(object = orange, file = '../../../data/orange_juice_customer_data.csv')
# the orange juice customer data file ----
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
write.csv(object = orange, file = '../../../data/orange_juice_customer_data.csv')
write.csv(orange, file = '../../../data/orange_juice_customer_data.csv')
set.seed(1)
trainset_row_numbers <- createDataPartition(orange$Purchase, p = 0.8, list = F) #we are
trainset_row_numbers
training_data <- orange[trainset_row_numbers, ]
training_data
trainset_row_numbers
# Step 2: Create the test dataset
testing_data <- orange[-trainset_row_numbers, ]
2:ncol(training_data)
# let's store the predictor and response variables
response_var <- training_data$Purchase
predictor_vars <- training_data[2:ncol(training_data), ]
library(skimr)
skimmed <- skim_to_wide(training_data)
skimmed[, c(1:5, 9:11, 13, 15:16)]
skimmed
skimmed
skimmed[, c(1:5, 9:11, 13, 15:16)] #choose to view certain variables of the output
missing_data_model <- preProcess(training_data, method = 'knnImpute')
missing_data_model
# input the missing values using the model on itself ====
library('RNN')
# input the missing values using the model on itself ====
library('RANN')
training_data_inputed <- predict(missing_data_model, newdata = training_data)
training_data_inputed
anyNA(training_data_inputed)
skimmed
# One-hot encoding ----
#' Creating dummy variables is converting a categorical variable to as many
#' binary variables as there are categories.
dummies_model <- dummyVars(Purchase ~ ., data = training_data)
dummies_model
dummies_model$lvls
#' Create the dummy variables using predict. The Response variable (Purchase) will not
#' be present in the result.
training_data_mat <- predict(dummies_model, newdata = training_data)
dummies_model
#' Create the dummy variables using predict. The Response variable (Purchase) will not
#' be present in the result, hence, the warning message.
training_data_matrix <- predict(dummies_model, newdata = training_data)
training_data_matrix
#' Create the dummy variables using predict. The Response variable (Purchase) will not
#' be present in the result, hence, the warning message.
training_data <- as.data.frame(predict(dummies_model, newdata = training_data))
training_data
#' Create the dummy variables using predict. The Response variable (Purchase) will not
#' be present in the result, hence, the warning message.
training_data <- data.frame(predict(dummies_model, newdata = training_data))
#' Create the dummy variables using predict. The Response variable (Purchase) will not
#' be present in the result, hence, the warning message.
training_data <- as.data.frame(predict(dummies_model, newdata = training_data))
source('C:/Users/Azam/GitRepositories/ds_ml/scripts/r-scripts/ds_ml_r_scripts/caret_tutorial.R', echo=TRUE)
training_data_df
str(training_data_df)
# Data transformation (as needed) ----'
#' There are many transformation functions in the caret package that can be used
#' based on the desired transformation but here, we'll use the range option to
#' transform the data to be between 0 and 1.
#'
prerocess_range_model <- preProcess(training_data_df, method = 'range')
training_data <- predict(preProcess_range_model, newdata = training_data)
# Data transformation (as needed) ----'
#' There are many transformation functions in the caret package that can be used
#' based on the desired transformation but here, we'll use the range option to
#' transform the data to be between 0 and 1.
#'
preProcess_range_model <- preProcess(training_data_df, method = 'range')
training_data <- predict(preProcess_range_model, newdata = training_data)
preProcess_range_model
training_data <- predict(preProcess_range_model, newdata = training_data_df)
# Append the Response variable
training_data$Purchase <- response_var
apply(training_data[, 1:10], 2, FUN = function(x){c('min' = min(x), 'max' = max(x))})
apply(training_data_df[, 1:10], 2, FUN = function(x){c('min' = min(x), 'max' = max(x))})
# Data transformation (as needed) ----'
#' There are many transformation functions in the caret package that can be used
#' based on the desired transformation but here, we'll use the range option to
#' transform the data to be between 0 and 1.
#'
preProcess_range_model <- preProcess(training_data_df, method = 'range')
training_data <- predict(preProcess_range_model, newdata = training_data_df)
# Append the Response variable
training_data$Purchase <- response_var
apply(training_data[, 1:10], 2, FUN = function(x){c('min' = min(x), 'max' = max(x))})
library(caret)
# The orange juice customer data file ----
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
# View(orange)
#' this is not part of the tutorial but I want to save the data in case it becomes
#' unavailable in the future
# write.csv(orange, file = '../../../data/orange_juice_customer_data.csv')
# Test and training sets ----
#' split the data into 80% training and 20% test sets
set.seed(1)
# Step 1: Get row numbers for the training data
trainset_row_numbers <- createDataPartition(orange$Purchase, p = 0.8, list = F)
# Step 2: Create the training  dataset
training_data <- orange[trainset_row_numbers, ]
# Step 3: Create the test dataset
testing_data <- orange[-trainset_row_numbers, ]
# let's store the predictor and response variables
response_var <- training_data$Purchase
predictor_vars <- training_data[2:ncol(training_data), ]
# Descriptive statistics
library(skimr)
skimmed <- skim_to_wide(training_data)
skimmed[, c(1:5, 9:11, 13, 15:16)] #choose to view certain variables of the output
# Missing value imputation with k-nearest neigbor prediction ----
# The missing values model ====
missing_data_model <- preProcess(training_data, method = 'knnImpute')
missing_data_model
# Input the missing values using the model on itself ====
library('RANN')
training_data_inputed <- predict(missing_data_model, newdata = training_data)
training_data_inputed
anyNA(training_data_inputed)
library(caret)
# The orange juice customer data file ----
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
# View(orange)
#' this is not part of the tutorial but I want to save the data in case it becomes
#' unavailable in the future
# write.csv(orange, file = '../../../data/orange_juice_customer_data.csv')
# Test and training sets ----
#' split the data into 80% training and 20% test sets
set.seed(1)
# Step 1: Get row numbers for the training data
trainset_row_numbers <- createDataPartition(orange$Purchase, p = 0.8, list = F)
set.seed(1)
# The orange juice customer data file ----
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
orange <- read.csv(orange, file = '../../../data/orange_juice_customer_data.csv')
orange <- read.csv('../../../data/orange_juice_customer_data.csv')
set.seed(1)
# Step 1: Get row numbers for the training data
trainset_row_numbers <- createDataPartition(orange$Purchase, p = 0.8, list = F)
# Step 2: Create the training  dataset
training_data <- orange[trainset_row_numbers, ]
# Step 3: Create the test dataset
testing_data <- orange[-trainset_row_numbers, ]
# let's store the predictor and response variables
response_var <- training_data$Purchase
predictor_vars <- training_data[2:ncol(training_data), ]
library(skimr)
skimmed <- skim_to_wide(training_data)
skimmed[, c(1:5, 9:11, 13, 15:16)] #choose to view certain variables of the output
# The missing values model ====
missing_data_model <- preProcess(training_data, method = 'knnImpute')
missing_data_model
# Input the missing values using the model on itself ====
library('RANN')
training_data_inputed <- predict(missing_data_model, newdata = training_data)
training_data_inputed
anyNA(training_data_inputed) #check if there are any NAs anywhere in the data
# One-hot encoding ----
# Creating dummy variables ====
#' That is, converting a categorical variable to as many
#' binary variables as there are categories.
dummies_model <- dummyVars(Purchase ~ ., data = training_data)
dummies_model
#' Create the dummy variables using predict. The Response variable (Purchase) will not
#' be present in the result, hence, the warning message.
training_data_matrix <- predict(dummies_model, newdata = training_data)
training_data_df <- as.data.frame(training_data_matrix)
str(training_data_df)
# Data transformation (as needed) ----'
#' There are many transformation functions in the caret package that can be used
#' based on the desired transformation but here, we'll use the range option to
#' transform the data to be between 0 and 1.
#'
preProcess_range_model <- preProcess(training_data_df, method = 'range')
training_data <- predict(preProcess_range_model, newdata = training_data_df)
# Append the Response variable
training_data$Purchase <- response_var
apply(training_data[, 1:10], 2, FUN = function(x){c('min' = min(x), 'max' = max(x))})
training_data_matrix
training_data_df <- data.frame(training_data_matrix)
str(training_data_df)
anyNA(training_data_df)
# One-hot encoding ----
# Creating dummy variables ====
#' That is, converting a categorical variable to as many
#' binary variables as there are categories.
dummies_model <- dummyVars(Purchase ~ ., data = training_data_inputed)
dummies_model
#' Create the dummy variables using predict. The Response variable (Purchase) will not
#' be present in the result, hence, the warning message.
training_data_matrix <- predict(dummies_model, newdata = training_data_inputed)
training_data_df <- data.frame(training_data_matrix)
str(training_data_df)
anyNA(training_data_df)
# Data transformation (as needed) ----'
#' There are many transformation functions in the caret package that can be used
#' based on the desired transformation but here, we'll use the range option to
#' transform the data to be between 0 and 1.
#'
preProcess_range_model <- preProcess(training_data_df, method = 'range')
training_data_final <- predict(preProcess_range_model, newdata = training_data_df)
# Append the Response variable
training_data_final$Purchase <- response_var
apply(training_data[, 1:10], 2, FUN = function(x){c('min' = min(x), 'max' = max(x))})
apply(training_data_final[, 1:10], 2, FUN = function(x){c('min' = min(x), 'max' = max(x))})
feature_plots <- featurePlot(x = trainData[, 1:18],
y = trainData$Purchase,
plot = "box")
feature_plots <- featurePlot(x = training_data_final[-1, ],
y = training_data_final$Purchase,
plot = "box")
ncol(training_data_final)
feature_plots <- featurePlot(x = training_data_final[ , 1:18],
y = training_data_final$Purchase,
plot = "box")
feature_plots
feature_plots <- featurePlot(x = training_data_final[ , 1:18],
y = training_data_final$Purchase
, plot = "box"
, strip=strip.custom(par.strip.text=list(cex=.7))
, scales = list(x = list(relation = "free"),
y = list(relation = "free")
)
)
feature_plots
featurePlot(x = training_data_final[ , 1:18],
y = training_data_final$Purchase
, plot = "strip"
, strip = strip.custom(par.strip.text = list(cex = 0.7))
, scales = list(x = list(relation = "free"),
y = list(relation = "free"))
)
featurePlot(x = training_data_final[ , 1:18],
y = training_data_final$Purchase
, plot = "density"
, strip = strip.custom(par.strip.text = list(cex = 0.7))
, scales = list(x = list(relation = "free"),
y = list(relation = "free"))
)
featurePlot(x = training_data_final[ , 1:18],
y = training_data_final$Purchase
, plot = "box"
, strip = strip.custom(par.strip.text = list(cex = 0.7))
, scales = list(x = list(relation = "free"),
y = list(relation = "free"))
)
feature_box_plots <- featurePlot(x = training_data_final[ , 1:18],
y = training_data_final$Purchase
, plot = "box"
, strip = strip.custom(par.strip.text = list(cex = 0.7))
, scales = list(x = list(relation = "free"),
y = list(relation = "free"))
)
feature_density_plots <- featurePlot(x = training_data_final[ , 1:18],
y = training_data_final$Purchase
, plot = "density"
, strip = strip.custom(par.strip.text = list(cex = 0.7))
, scales = list(x = list(relation = "free"),
y = list(relation = "free"))
)
feature_density_plots
options(warn = -1) #' negative value means ignore warnings. Check the help file for more explanation
subsets <- c(1:5, 10, 15, 18)
subsets <- c(1:5, 10, 15, 18)
ctrl <- rfeControl(functions = rfFuncs,
method = "repeatedcv",
repeats = 5,
verbose = FALSE)
lmProfile <- rfe(x = training_data_final[, 1:18],
y = training_data_final$Purchase
, sizes = subsets
, rfeControl = ctrl
)
lmProfile
